{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personal Statement: Peter Dresslar, Applicant\n",
    "\n",
    "### Complex Systems Science MS, Arizona State University, Fall 2025\n",
    "\n",
    "*March, 2025*\n",
    "\n",
    "<div style=\"text-align: center; font-size: 24px; margin: 20px 0;\">\n",
    ". . .\n",
    "</div>\n",
    "\n",
    "This statement is available in its native format, a Jupyter Notebook, at:\n",
    "\n",
    "https://colab.research.google.com/github/peterdresslar/peterdresslar-asucss-f2025/blob/main/dresslar-personal-statement.ipynb\n",
    "\n",
    "The source code can be accessed from that link. Reviewers with the inclincation to do so are encouraged to please visit the online version.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# This cell handles setup - you can collapse it after running\n",
    "import sys, subprocess, importlib.util, requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Complex Systems Science?\n",
    "\n",
    "For a very long time, starting with Conwayʻs Game of Life on an Apple IIc(!), I have been fascinated with automata. I spent endless hours in University of Michigan (invariably freezing cold) computer labs toying with my own versions in Pascal and C, sometimes to the detriment of my actual homework. I dreamt of opening a cafe where the ceilings would run automata in LED light displays.\n",
    "\n",
    "Unsurprisingly, the usual transpired: I graduated, I grew up. Life happened.\n",
    "\n",
    "<div style=\"text-align: center; font-size: 24px; margin: 20px 0;\">\n",
    ". . .\n",
    "</div>\n",
    "\n",
    "Years later, a couple of events caused those old interests to flicker back to life. My work has recently focused increasingly on AI, and with the advent of large language models (LLMs), I again began experimenting a bit with automata. I began prototypes like the following code in early 2023, asking ChatGPT to output the first few steps of a basic, well-known computational system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000000000000001\n",
      "0000000000000011\n",
      "0000000000000111\n",
      "0000000000001110\n",
      "0000000000011101\n",
      "0000000000111011\n",
      "0000000001110111\n",
      "0000000011101110\n",
      "0000000111011101\n",
      "0000001110111011\n",
      "0000011101110110\n"
     ]
    }
   ],
   "source": [
    "# Here, weʻll call out to a service that is set up to respond to calls for OpenAIʻs models. The service is contained in the \n",
    "# main.py file of the repository containing this notebook.\n",
    "\n",
    "def ask_openai_something(prompt, model=\"gpt-3.5-turbo\", url=\"https://peterdresslar-asucss-f2025.onrender.com/ask\"):\n",
    "    response = requests.post(url, json={\"prompt\": prompt, \"model\": model})\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[\"response\"]\n",
    "    else:\n",
    "        return f\"Error: {response.status_code}, {response.text}\"\n",
    "\n",
    "\n",
    "prompt = \"\"\"\n",
    "Please output the first 10 steps of Rule 110,\n",
    "Given a 16 cell cylinder,\n",
    "with the initial condition of \n",
    "fifteen 0s followed by a 1 (left to right).\n",
    "\n",
    "Please think through the steps carefully for yourself. As a reminder, the rules of Rule 110 are:\n",
    "\n",
    "Pattern | Next State\n",
    "——--|———-\n",
    "111 | 0\n",
    "110 | 1\n",
    "101 | 1\n",
    "100 | 0\n",
    "011 | 1\n",
    "010 | 1\n",
    "001 | 1\n",
    "000 | 0\n",
    "\n",
    "Kindly respond only with the output values, no other text. Make sure to include the initial condition with your list of ten steps. \n",
    "So, your output should be a list of eleven cylinder conditions. Thanks!\n",
    "\"\"\"\n",
    "\n",
    "old_model = \"gpt-3.5-turbo\"\n",
    "\n",
    "print(ask_openai_something(prompt, old_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some readers might be aware that Rule 110 is a computable automaton based on a set of simple rules, as formally described by Stephen Wolfram in 1983. Seen in the code and results above, the rules generate outputs that turn out not only to be complex, but [Turing complete](https://en.wikipedia.org/wiki/Turing_completeness). \n",
    "\n",
    "For reference, the tenth iteration of Rule 110 after the starting step is, under the conditions set above, `0000011100001101`.\n",
    "\n",
    "The results above are from ChatGPT 3.5, a model delivered to the public around 30 months ago, as of this writing. If you re-run the code in the notebook on your own, it will almost certainly not make it correctly to step 10. However, the model made enough valiant attempts, even in 2023, that I suspected it was only a matter of time before the approach would work.\n",
    "\n",
    "Letʻs try again, this time with OpenAIʻs most powerful model as of this writing: [o1](https://openai.com/o1/), recently released to the public."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1  \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1  \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1  \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1  \n",
      "0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1  \n",
      "0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1  \n",
      "0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 1  \n",
      "0 0 0 0 0 0 0 0 1 1 0 1 0 1 1 1  \n",
      "0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 1  \n",
      "0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 1  \n",
      "0 0 0 0 0 1 1 1 0 0 0 0 1 1 0 1  \n"
     ]
    }
   ],
   "source": [
    "# Set up call to OpenAIʻs o1 Reasoning model. It can take a few minutes to respond!\n",
    "\n",
    "prompt = prompt # see above.\n",
    "\n",
    "new_model = \"o1\"\n",
    "\n",
    "print(ask_openai_something(prompt, new_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was indeed only a matter of time: about a year and a half, as it turns out. OpenAI o1, along with a few other frontier LLMs[1], can, with some frequency, get Rule 110 right. \n",
    "\n",
    "Something truly profound is happening here, at least on a small scale. Through the results above, we might infer that there is at least one other class of entity in the universe, outside of human beings, that can emulate... *not* compute, but *think through*... an automaton for several steps in a row.[2] For some small degree of universality, we humans belonged to a class last year that is no longer ours alone. Things changed, and are changing.\n",
    "\n",
    "My conclusion is that there is no more exciting potential intellectual interface out there than the following tripartite:\n",
    "\n",
    "- Human intuition and volition\n",
    "- Artificial Intelligence reasoning\n",
    "- Mundane, universal, and cosmic complexity\n",
    "\n",
    "<div style=\"text-align: center; font-size: 24px; margin: 20px 0;\">\n",
    ". . .\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speaking of mundanity: I mentioned above that *two* things happened. \n",
    "\n",
    "The other one was: I currently work for American Samoa Community College, which, as of December 2024, was working to establish remote courses for the Pacific market.[3] As the manager of our technology integration effort, I signed up for ASUʻs online courses simply to gather competitive intelligence. \n",
    "\n",
    "I was browsing various course catalogues from the university when Professor Applegateʻs Complexity Economics course description came across my search bar. That led me to her agent based models (ABMs) on CoMSES, a few of which I downloaded and worked with, and suddenly I was hooked. I had been experimenting with some minor computational toys... now *these* were automata!\n",
    "\n",
    "So, I signed up for the CAS 543. By the first weekʻs assignment I was passionate about the work. By about week five I was dreaming about models. \n",
    "\n",
    "Here is some of the work that I posted in class:\n",
    "\n",
    "- [The Subliminal Wolf](https://colab.research.google.com/github/peterdresslar/the-subliminal-wolf/blob/main/the_subliminal_wolf.ipynb), an attempt at discretizing a continuous dynamic system into an agent based model, along a discussion of agency itself.\n",
    "- [Electric Mesa](https://colab.research.google.com/github/peterdresslar/electric-mesa/blob/main/notebooks/colab_only_electric_mesa.ipynb), in which I convert a class-supplied ABM into the Python Mesa modelling framework and then experiment with embedding it in the notebook itself.\n",
    "- A [complexity economics-based discussion](https://colab.research.google.com/github/peterdresslar/regarding-r-greaterthan-g-so-what/blob/main/RegardingRGreaterThanGSoWhat.ipynb) (no code!) of the Gregory Mankiw response to Thomas Piketty.\n",
    "\n",
    "Hopefully these examples illustrate the degree to which I have been completely turned onto the ideas of complexity science, agent based modelling, and, to the degree my abilities allow, the underlying formalisms and mathematics. \n",
    "\n",
    "When we consider these and other agent based models, along with the tiny experiment described above, some practical applications immediately present themselves. I have begun work, with Professor Applegateʻs guidance, on an ABM based on the classical Lotka-Volterra ecological system of formulae. We are applying AI in an effort to answer a research question: \n",
    "\n",
    "> \"Do LLM agents produce emergent system-level stability or new behavior in a well-known dynamic model?\"\n",
    "\n",
    "The proof of concept illustrated above leads me to think that the answer could be, \"yes.\" We have some thought-provoking results so far, ones that I believe can be developed into a formal paper. If you are reading this and interested to know more—by all means, [contact me](mailto:pdressla@asu.edu).\n",
    "\n",
    "From there, I am excited to expand upon the approach, and would be particularly pleased to network with other students with various expertises and backgrounds to find new avenues where we might be able to solve some of the (seemingly endless) problems facing the world today. I expect that beyond ecology, we might find particular success investigating traditional problems from economics, sociology, and perhaps even the pursuit of science itself. That would naturally connect with the kinds of research being produced, for instance, at the ASU-SFI Center for Biosocial Complex Systems, or perhaps Decision Theater, among other research efforts at ASU.\n",
    "\n",
    "Itʻs no secret that our present-day world is reeling from challenges, and here in the Pacific region the confluence of economic, political, and environmental conditions is overwhelming. It is a region dying for solutions: sometimes literally so. The ability to convincingly demonstrate new paths forward would be worth almost any amount of effort.\n",
    "\n",
    "In summary, I feel that my experiences with computational models, my track record in public-sector technology deployments and service, and my ongoing agent-based modeling research align perfectly with the mission and research areas of the Complex Systems Science MS at ASU. I feel that I can contribute immediately to the program by networking with like-minded students within and around ASU. I hope to continue my research into the future. And, I would be delighted to contribute, using my background in higher education, program development, and fundraising, to help the program with sustainability, should that be of interest to leadership there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-size: 24px; margin: 20px 0;\">\n",
    ". . .\n",
    "</div>\n",
    "\n",
    "### About Me\n",
    "\n",
    "I'm the founder and executive director of Pacific Broadband and Digital Equity, where I work with community anchor institutions across the Pacific region to improve digital access. My background spans technology leadership, government service, and entrepreneurship—including roles as Commonwealth Broadband Lead for CNMI and Territorial Broadband Coordinator for American Samoa, where I secured over $125 million in federal funding. Previously, I founded Elevada Inc., a data services company serving pharmaceutical clients, and served as Adjunct Faculty at the University of Michigan College of Pharmacy. My technical expertise includes full-stack development, cloud infrastructure, and AI systems. I'm particularly interested in how modern technology and complex systems can address societal challenges, which has led me to explore the intersection of agent-based modeling and artificial intelligence in my recent work.\n",
    "\n",
    "I live in Honolulu, Hawai‘i.\n",
    "\n",
    "I have identities on [Github](https://github.com/peterdresslar), [LinkedIn](https://www.linkedin.com/in/peter-dresslar/), [ORCiD](https://orcid.org/0000-0002-3893-4103), and, I guess, [Medium](https://medium.com/@peterdresslar).\n",
    "\n",
    "### Notes\n",
    "\n",
    "[1] [Deepseek R1](https://www.deepseek.com/) can sometimes get Rule110 correct past ten steps. [Claude Sonnet v3.7](https://console.anthropic.com/workbench) can sometimes get to about step eight unscathed, and its \"reasoning\" outputs are enlightening, but Anthropicʻs rate limits can be challenging. A more formal investigation might be of interest.\n",
    "\n",
    "[2] I recognize that characterizing what LLMs do as \"thinking through\" rather than \"computing\" may be controversial. My position is that when an LLM correctly executes Rule 110 without being explicitly programmed to do so, it's engaging in a form of reasoning that's qualitatively different from traditional algorithmic computation. The model isn't executing a hardcoded Rule 110 algorithm; it's using its learned representations to simulate the rule's behavior—a process more akin to how humans reason through problems than how traditional computers execute instructions. This distinction becomes important when considering the implications for complex systems modeling, where emergent behaviors often arise from simple rules applied through distributed cognition rather than centralized computation.\n",
    "\n",
    "[3] Today, the college is merely struggling to survive, for reasons with which the reader will likely be familiar.\n",
    "\n",
    "### References\n",
    "\n",
    "Applegate, J. M. (2018, July 13). *Emergent Firms Model* (Version 1.0.0) [Computer software]. CoMSES Computational Model Library. https://doi.org/10.25937/6t61-qm82\n",
    "\n",
    "Cook, M. (2004). [Universality in elementary cellular automata](https://wpmedia.wolfram.com/sites/13/2018/02/15-1-1.pdf). Complex Systems, 15(1), 1–40.\n",
    "\n",
    "Gardner, M. (1970). Mathematical Games: The fantastic combinations of John Conway’s new solitaire game “Life.” Scientific American, 223(4), 120–123.\n",
    "\n",
    "Wolfram, S. (2002). *A new kind of science*. Wolfram Media.\n",
    "\n",
    "Wolfram Research, Inc. (2024). [Rule 110](https://www.wolframalpha.com/input?i=rule+110). In Wolfram|Alpha Notebook Edition. Wolfram Research, Inc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
